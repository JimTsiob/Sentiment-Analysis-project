{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-17T14:59:13.252045Z",
     "iopub.status.busy": "2024-04-17T14:59:13.251463Z",
     "iopub.status.idle": "2024-04-17T14:59:13.274060Z",
     "shell.execute_reply": "2024-04-17T14:59:13.272758Z",
     "shell.execute_reply.started": "2024-04-17T14:59:13.251980Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score,roc_curve\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from pandarallel import pandarallel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T14:59:54.588486Z",
     "iopub.status.busy": "2024-04-17T14:59:54.588088Z",
     "iopub.status.idle": "2024-04-17T14:59:54.766354Z",
     "shell.execute_reply": "2024-04-17T14:59:54.764647Z",
     "shell.execute_reply.started": "2024-04-17T14:59:54.588456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Tech support is the worst</td>\n",
       "      <td>1265760000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>Screws were missing from the bracket and beaut...</td>\n",
       "      <td>Spend a little more and get much better.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>Trouble connecting and staying connected via b...</td>\n",
       "      <td>1499644800</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>I purchased this unit for our RV to replace an...</td>\n",
       "      <td>Receiver Offers a Lot of Flexibility &amp; Complexity</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>It works.  Nuff said but the review requires 1...</td>\n",
       "      <td>It's a cable</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  vote  reviewTime  \\\n",
       "0        2     0  2010-02-10   \n",
       "1        2     0  2016-10-24   \n",
       "2        1     0  2017-07-10   \n",
       "3        4     5  2013-05-02   \n",
       "4        3     0  2013-01-04   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0                          Tech support is the worst   \n",
       "1  Screws were missing from the bracket and beaut...   \n",
       "2  Trouble connecting and staying connected via b...   \n",
       "3  I purchased this unit for our RV to replace an...   \n",
       "4  It works.  Nuff said but the review requires 1...   \n",
       "\n",
       "                                             summary     Label  \n",
       "0                                         1265760000  NEGATIVE  \n",
       "1           Spend a little more and get much better.  NEGATIVE  \n",
       "2                                         1499644800  NEGATIVE  \n",
       "3  Receiver Offers a Lot of Flexibility & Complexity  POSITIVE  \n",
       "4                                       It's a cable   NEUTRAL  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_dataset = pd.read_csv('../input/amazon-reviews-2018-electronics/labeled_electronics_dataset.csv')\n",
    "\n",
    "electronics_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN (before cleanup) ?: \n",
      " overall       0\n",
      "vote          0\n",
      "reviewTime    0\n",
      "reviewText    1\n",
      "summary       0\n",
      "Label         0\n",
      "dtype: int64\n",
      "NaN (after cleanup) ?: \n",
      " overall       0\n",
      "vote          0\n",
      "reviewTime    0\n",
      "reviewText    0\n",
      "summary       0\n",
      "Label         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(\"NaN (before cleanup) ?: \\n\", electronics_dataset.isnull().sum())\n",
    "\n",
    "electronics_dataset['reviewText'] = electronics_dataset['reviewText'].fillna('')\n",
    "\n",
    "print(\"NaN (after cleanup) ?: \\n\", electronics_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4268cdf1a94319b6cec9c574800dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4953), Label(value='0 / 4953'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46a15742d8445d6957d39092431e270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4953), Label(value='0 / 4953'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandarallel\\core.py\", line 158, in __call__\n    results = self.work_function(\n              ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandarallel\\data_types\\series.py\", line 26, in work\n    return data.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py\", line 4760, in apply\n    ).apply()\n      ^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py\", line 1207, in apply\n    return self.apply_standard()\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py\", line 1287, in apply_standard\n    mapped = obj._map_values(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py\", line 921, in _map_values\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py\", line 1814, in map_array\n    return lib.map_infer(values, mapper, convert=convert)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"lib.pyx\", line 2917, in pandas._libs.lib.map_infer\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandarallel\\progress_bars.py\", line 214, in closure\n    return user_defined_function(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_33380\\773283359.py\", line 21, in remove_stopwords\nNameError: name 'word_tokenize' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m     words \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[1;32m---> 25\u001b[0m electronics_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m electronics_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mparallel_apply(remove_stopwords)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Lemmatization\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_word\u001b[39m(text):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandarallel\\core.py:444\u001b[0m, in \u001b[0;36mparallelize_with_pipe.<locals>.closure\u001b[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mError:\n\u001b[0;32m    442\u001b[0m         progress_bars\u001b[38;5;241m.\u001b[39mset_error(worker_index)\n\u001b[1;32m--> 444\u001b[0m results \u001b[38;5;241m=\u001b[39m results_promise\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data_type\u001b[38;5;241m.\u001b[39mreduce(results, reduce_extra)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "# Text preprocessing for reviewText column\n",
    "# Lower all text\n",
    "\n",
    "electronics_dataset['reviewText'] = electronics_dataset['reviewText'].str.lower()\n",
    "\n",
    "# Initialize pandarallel\n",
    "# I used pandarallel because it applies the functions much faster than a normal pandas apply.\n",
    "pandarallel.initialize(nb_workers=4,progress_bar=True)\n",
    "\n",
    "# Remove all special characters\n",
    "def remove_special_chars(text):\n",
    "    return ''.join(x if x.isalnum() else ' ' for x in text)\n",
    "\n",
    "electronics_dataset['reviewText'] = electronics_dataset['reviewText'].parallel_apply(remove_special_chars)\n",
    "\n",
    "# get stopwords.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stop_words\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    return [x for x in words if x not in stop_words]\n",
    "\n",
    "\n",
    "electronics_dataset['reviewText'] = electronics_dataset['reviewText'].parallel_apply(remove_stopwords)\n",
    "\n",
    "# Lemmatization\n",
    "def lemmatize_word(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    return \" \".join([wordnet.lemmatize(word) for word in text])\n",
    "\n",
    "electronics_dataset['reviewText'] = electronics_dataset['reviewText'].parallel_apply(lemmatize_word)\n",
    "\n",
    "print('Example of preprocessing train: ')\n",
    "print(electronics_dataset['reviewText'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4818115,
     "sourceId": 8147371,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
